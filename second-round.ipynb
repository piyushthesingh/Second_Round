{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**The code is not** even half **complete** yet; I am very sorry for that. \n\nWe get to know about the assessment yesterday afternoon only, and as I had classes till 4 PM and a class test this morning, I was unable to write a solid code.\n\nBesides, this was my first code which included image processing, major issue I faced was with reading the image, which took the major portion of my time.","metadata":{}},{"cell_type":"markdown","source":"# Importing Required Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # To create creating static, animated, and/or interactive visualizations","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**Reading the files(s), starting with stock4.jpg in this case**","metadata":{}},{"cell_type":"code","source":"img = cv2.imread('../input/image-2/stock4.jpg', 0)","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Approach to find the total number of counts\n\n**Specifically for the stack of grey trays** named as \"stock1.jpg\" and \"stock2.jpg\" **and for the stack of brown boxes** named as \"stock3.jpg\" and \"stock4.jpg\"\n\nApproach was to run code for the cases, grey trays first, and if count is 'zero' or a small number say '2', run the code for brown boxes, and whichever count is bigger, that is the total number of counts in the image.\n\nFor **Grey trays**, idea was to provide HSV bounds (lower and upper) as per the colour of trays that we can observe from the images, and count the number of distinct objects having the colour between these values.\n\nFor **brown boxes**, as brown is not a very different color, idea was to count the number of green patches that are visible on the boxes, and white patches as every box has a sticker on it. But green is the color of side bar as well, as I will be considering upper bound as the **Army Green** color and the lower bound as the **Olive Green** color. If number of green patches equal to the number of white patches +- 3 (as labeling on the stack is also there), then number of green patches is equal to the number of boxes. Else, If the difference is more, divide the number of green patches by 'two' and that should be the total number of boxes in the stack.","metadata":{}},{"cell_type":"code","source":"#Finding number of boxes\nlow_green = np.array([60, 100, 25])\nhigh_green = np.array([68, 64, 29])\ngreenMask = cv2.inRange(img, low_brown, high_brown)\nprint(greenMask.shape)\n\n#Finding number of trays\nlow_grey = np.array([0, 0, 80.39])\nhigh_grey = np.array([185, 16.44, 28.63])\ngreyMask = cv2.inRange(img, low_grey, high_grey)\nprint(greyMask.shape)\n","metadata":{"trusted":true},"execution_count":12,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-d538e21a9277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlow_green\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhigh_green\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m68\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m29\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgreenMask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minRange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_brown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh_brown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgreenMask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /tmp/pip-req-build-tk9iuyva/opencv/modules/core/src/arithm.cpp:1758: error: (-209:Sizes of input arguments do not match) The lower boundary is neither an array of the same size and same type as src, nor a scalar in function 'inRange'\n"],"ename":"error","evalue":"OpenCV(4.5.1) /tmp/pip-req-build-tk9iuyva/opencv/modules/core/src/arithm.cpp:1758: error: (-209:Sizes of input arguments do not match) The lower boundary is neither an array of the same size and same type as src, nor a scalar in function 'inRange'\n","output_type":"error"}]},{"cell_type":"markdown","source":"# Approach to Identify the right angles\n \n**Specifically for the door frames** named from 'frame1.jpg' to 'frame8.jpg' \n\nAs images are randomly taken with no reference or no specific angle, the approach was to lift the images if possible or try to crop and then stretch with some reference. For the solution, the idea was to try to do that manually, similar to the 'Adobe Scan,' and then let the code do the job, like drawing the lines at every boundary and try to calculate the angle between them. An angle between 87degrees to 93 degrees should be considered as the right angle. This angle calculation might be possible using **line hue**.\n\nAnother approach was to find a dataset with images of right angles as 1 and other angles as 0 and train the machines to try to match the image with the dataset. That can be done using library **tensor flow**","metadata":{}},{"cell_type":"markdown","source":"# Approach to Identify if there are any welding deposits, aggregations\n\n**Specifically for the door frames** named from 'frame1.jpg' to 'frame8.jpg' \n\nThe approach was to find a dataset containing images of the welded joints having excessive and unnecessary filler as 'one' and fair welding as 'zero,' and using this dataset, train the machine to try to find the number of such welded deposits having values 'one.'","metadata":{}}]}